{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Errors\n",
    "This notebook computes errors and various accuracy measures using PredictionResults() object and files generated by merge_data as inputs. This notebook computes errors and measures **for each station and for each direction separately**. The steps of the code are as follows:\n",
    "- computes Mean Absolute Relative Error (MARE) and MAE to capacity ratio (ECR) depending on volume / capacity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters and initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRAN_15_MIN = True\n",
    "CHANGE_TO_ONE_HOUR = False # True if you want to change granulation from 15 minutes to 1 hour. GRAN_15_MIN must also be true\n",
    "\n",
    "\n",
    "print ('You are working with {} granulated data.'\n",
    "       .format('15 minute' if GRAN_15_MIN else 'hourly'))\n",
    "\n",
    "if CHANGE_TO_ONE_HOUR and (not GRAN_15_MIN):\n",
    "    CHANGE_TO_ONE_HOUR = False\n",
    "    print ('15 min granulation not set. CHANGE_TO_ONE_HOUR automatically set to false.')\n",
    "    \n",
    "print ('Data will {}be converted from 15 min to one hour format.'\n",
    "       .format('' if CHANGE_TO_ONE_HOUR else 'NOT '))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_shifted_data(df):\n",
    "    \"\"\"\n",
    "    Adds columns gps_wc{1/2/3}_INTIRX_m{15/30/45} to dataframe.\n",
    "    Adds column  'datetime' if does not exists. Otherwise overwrites it.\n",
    "    Changes atr_volume to present the cumulative count from the last hour (not from the last 15 minutes)\n",
    "    \"\"\"\n",
    "    \n",
    "    #df['datetime'] = df['datetime'] = pd.to_datetime(df.unix_ts,unit='s')#, utc='US/Eastern')   \n",
    "    df['datetime'] = pd.to_datetime(df.date + ' ' + df.time)\n",
    "    \n",
    "    toShiftCols = ['gps_pt1_wc1', 'gps_pt2_wc1', 'gps_pt2_wc2', 'gps_pt2_wc3', 'volume']\n",
    "    tmp = df[['tmc', 'datetime'] + toShiftCols].copy()\n",
    "    for tshift in [15, 30, 45]:\n",
    "        tmp2 = tmp.copy()\n",
    "        cols = ['{}_m{}'.format(x, tshift) if x[-5:] == 'INRIX' or x=='volume' else x for x in list(tmp.columns)]\n",
    "        tmp2.columns = cols\n",
    "        tmp2.datetime = tmp2.datetime + pd.Timedelta(minutes=tshift)\n",
    "        sys.stdout.write('Merging for {} minutes.  \\r'.format(tshift))\n",
    "        df = df.merge(tmp2, on=['tmc', 'datetime'], how='left')    \n",
    "\n",
    "\n",
    "    df = df.dropna(subset=['volume_m{}'.format(x) for x in [15, 30, 45]])\n",
    "    df = df[df.datetime >= '2018-01-02 01:00:00']\n",
    "    for c in toShiftCols:\n",
    "        df[c] = df[[c, '{}_m15'.format(c), '{}_m30'.format(c), '{}_m45'.format(c)]].sum(axis=1)\n",
    "        df = df.drop(['{}_m15'.format(c), '{}_m30'.format(c), '{}_m45'.format(c)], axis=1)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = './Example/results/DeepAndWide/20200418_results_all.csv'\n",
    "file_id = '_'.join(filename[:-4].split('/')[-2:])\n",
    "\n",
    "print (file_id)\n",
    "\n",
    "sys.stdout.write('Loading data...\\r')\n",
    "results_all = pd.read_csv(filename)\n",
    "original_shape = results_all.shape\n",
    "results_all.rename(inplace=True, columns=\n",
    "               {'count_location' : 'station', \n",
    "                'osm_highway': 'Road_type',\n",
    "                'count_total' : 'volume',\n",
    "                'pred' : 'pred_ANN',\n",
    "               })\n",
    "\n",
    "\n",
    "#print (results_all)\n",
    "#results_all['pred_ANN'] = results_all['pred_tti'] # FOR TESTING TTI RESULTS\n",
    "\n",
    "\n",
    "if CHANGE_TO_ONE_HOUR:\n",
    "    results_all['pred_ANN_NotNull'] = ~results_all.pred_ANN.isnull()\n",
    "    results_all = add_shifted_data(results_all)\n",
    "    results = results_all[results_all['pred_ANN_NotNull']].copy().drop('pred_ANN_NotNull', axis='columns')\n",
    "else:\n",
    "    results = results_all[~pd.isnull(results_all['pred_ANN']) ].copy()\n",
    "\n",
    "\n",
    "print ('Original results_all table had {} rows'.format(original_shape[0]))\n",
    "print ('Results_all table has {} rows'.format(len(results_all)))\n",
    "print ('Results table has {} rows ({:.2f} %)'.format(len(results), 100.0 * len(results) / len(results_all)))\n",
    "\n",
    "\n",
    "colnames = ['gps_pt1_wc1', 'gps_pt2_wc1', 'gps_pt2_wc2', 'gps_pt2_wc3']\n",
    "results[colnames] = results[colnames].fillna(0)\n",
    "results['GPS'] = results[colnames].sum(axis=1)\n",
    "print (results.shape)\n",
    "print (results.columns)\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results.sort_values(['tmc', 'datetime_utc']).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute errors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = results.groupby('tmc').agg({'volume' : 'max'}).reset_index().rename(columns = {'volume' : 'capacityP'})\n",
    "results = results.merge(tmp, on='tmc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results['err_capacityT'] = np.abs(results['pred_ANN'] - results['volume']) / results['capacityT']\n",
    "results['err_capacityP'] = 100 * np.abs(results['pred_ANN'] - results['volume']) / results['capacityP']\n",
    "#results['mape'] = 100 * np.abs(results['pred_ANN'] - results['volume']) / results['volume']\n",
    "#results['smape'] = 200 * np.abs(results.pred_ANN - results.volume) / ( results.pred_ANN.abs() + results.volume.abs() ) \n",
    "#results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create list of parameters (locations, directions, road types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_list(rd_all, rd, listtype = 'tmc', verbose = 1):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        rd - dataframe with results\n",
    "        listtype:\n",
    "            'tmc' for stations\n",
    "            'type' for road type\n",
    "            'GPS' for number of GPS car observed\n",
    "            'observations' - number of data points (rows)\n",
    "    \"\"\"\n",
    "    stations = np.sort(pd.unique(rd['station']))\n",
    "    ret = []\n",
    "    if verbose > 0:\n",
    "        sys.stdout.write('Generating list of parameters for {}.                  \\r'.format(listtype))\n",
    "    for station in stations:\n",
    "        r_station = rd[rd['station'] == station]\n",
    "        directions = np.sort(pd.unique(r_station['tmc']))\n",
    "        for direction in directions:\n",
    "            if listtype == 'station':\n",
    "                ret.append(station)\n",
    "            elif listtype == 'tmc':\n",
    "                ret.append(direction)\n",
    "            elif listtype == 'frc':\n",
    "                rres = r_station[r_station['tmc'] == direction]\n",
    "                ret.append(rres.iloc[0]['frc'])\n",
    "            elif listtype == 'type':\n",
    "                rres = r_station[r_station['tmc'] == direction]\n",
    "                ret.append(rres.iloc[0]['Road_type'])\n",
    "            elif listtype == 'lanes':\n",
    "                rres = r_station[r_station['tmc'] == direction]\n",
    "                ret.append(rres.iloc[0]['thru_lanes'])\n",
    "            elif listtype == 'observations':\n",
    "                rres = r_station[r_station['tmc'] == direction]\n",
    "                ret.append(rres.shape[0])\n",
    "            elif listtype == 'GPS':\n",
    "                rres = r_station[r_station['tmc'] == direction]\n",
    "                ret.append(int(np.sum(rres['GPS'])))\n",
    "            elif listtype == 'volume':\n",
    "                rres = r_station[r_station['tmc'] == direction]\n",
    "                ret.append(int(np.sum(rres['volume'])))\n",
    "            elif listtype == 'CapacityP':\n",
    "                rres = r_station[r_station['tmc'] == direction]\n",
    "                ret.append(int(np.max(rres['volume'])))                \n",
    "\n",
    "    return ret\n",
    "                \n",
    "df_res = pd.DataFrame()\n",
    "                \n",
    "df_res['station'] = create_list(results_all, results, 'station')\n",
    "df_res['tmc'] = create_list(results_all, results, 'tmc')\n",
    "df_res['frc'] = create_list(results_all, results, 'frc')\n",
    "df_res['type'] = create_list(results_all, results, 'type')\n",
    "df_res['lanes'] = create_list(results_all, results, 'lanes')\n",
    "df_res['observations'] = create_list(results_all, results, 'observations')\n",
    "df_res['GPS'] = create_list(results_all, results, 'GPS')\n",
    "df_res['volume'] = create_list(results_all, results, 'volume')\n",
    "df_res['CapacityP'] = create_list(results_all, results, 'CapacityP')\n",
    "df_res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute and display $R^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def create_r2_table(rd):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        rd - DataFrame with results\n",
    "    \"\"\"\n",
    "    \n",
    "    res = pd.DataFrame(columns = ['station', 'tmc', 'r2'])\n",
    "    stations = np.sort(pd.unique(rd['station']))\n",
    "    i = 0\n",
    "    ret = []\n",
    "    for station in stations:\n",
    "        r_station = rd[rd['station'] == station]\n",
    "        directions = np.sort(pd.unique(r_station['tmc']))\n",
    "        for direction in directions:\n",
    "            rres = r_station[r_station['tmc'] == direction]\n",
    "            r2 = r2_score(rres['volume'], rres['pred_ANN'])\n",
    "            res.loc[i] = [station, direction, r2]\n",
    "            i += 1\n",
    "            #print (r2)\n",
    "            ret.append(r2)\n",
    "    return ret\n",
    "\n",
    "df_res['R2'] = create_r2_table(results.copy())\n",
    "df_res.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add errors to result table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = results.groupby('tmc').agg({\n",
    "    'mape' : np.average,\n",
    "    'smape' : np.average,\n",
    "    'err_capacityP' : np.average,\n",
    "    \n",
    "}).rename(columns={\n",
    "    'mape' : 'MAPE',\n",
    "    'smape' : 'SMAPE',\n",
    "    'err_capacityP' : 'EMFR'\n",
    "})\n",
    "df_res = df_res.merge(tmp, on='tmc')\n",
    "df_res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_error_table(rd, column='volume'):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        column - may be 'capacityP', 'capacityP85', 'capacityT' or 'volume'  \n",
    "    \"\"\"\n",
    "    \n",
    "    err = pd.DataFrame(columns = ['station', 'tmc', 'err_ '+ column])\n",
    "    stations = np.sort(pd.unique(rd['station']))\n",
    "    i = 0\n",
    "    ret = []\n",
    "    for station in stations:\n",
    "        r_station = rd[rd['station'] == station]\n",
    "        directions = np.sort(pd.unique(r_station['tmc']))\n",
    "        for direction in directions:\n",
    "            rres = r_station[r_station['tmc'] == direction]\n",
    "            e = np.average (rres['err_' + column] )\n",
    "            err.loc[i] = [station, direction, e]\n",
    "            i += 1\n",
    "            #print (e)\n",
    "            ret.append(e)\n",
    "    return ret\n",
    "\n",
    "\n",
    "\n",
    "# Old version, no need to use for MAPE, SMAPE and EMFR\n",
    "\n",
    "#df_res['ECTR'] = create_error_table(results.copy(), 'capacityT') # ECR-T\n",
    "#df_res['EMFR'] = create_error_table(results.copy(), 'capacityP') # ECR-P\n",
    "#df_res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percentiles for GPS coutns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res['GPS_avg'] = df_res.GPS / df_res.observations\n",
    "perc_33 = np.percentile(df_res.GPS_avg, 33)\n",
    "perc_67 = np.percentile(df_res.GPS_avg, 67)\n",
    "print (perc_33, perc_67)\n",
    "df_res['GPS_perc'] = 2\n",
    "df_res.loc[df_res.GPS_avg <= perc_33, 'GPS_perc'] = 1\n",
    "df_res.loc[df_res.GPS_avg >= perc_67, 'GPS_perc'] = 3\n",
    "print ('Perc 33: {}, Perc 67: {}'.format(perc_33, perc_67))\n",
    "print ('')\n",
    "df_res.groupby('GPS_perc').agg({\n",
    "    'R2' : [np.mean, np.median],\n",
    "    'MAPE' : [np.mean, np.median],\n",
    "    'EMFR' : [np.mean, np.median],\n",
    "    'observations' : np.sum\n",
    "    })\n",
    "\n",
    "\n",
    "if CHANGE_TO_ONE_HOUR or (not GRAN_15_MIN): # 1 hour granulation\n",
    "    gran_mul = 1\n",
    "else:\n",
    "    gran_mul = 4\n",
    "    \n",
    "\n",
    "print ('Granulation: {} minutes'.format(60 / gran_mul))    \n",
    "for i in range (1, 4):\n",
    "    print ('GPS_perc {}: {:.2f} - {:.2f}'\n",
    "           .format(i, gran_mul * df_res.GPS_avg[df_res.GPS_perc == i].min(),\n",
    "                   gran_mul * df_res.GPS_avg[df_res.GPS_perc == i].max()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Volume thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 1000\n",
    "df_res['Vol_thresh'] = gran_mul * df_res.volume / df_res.observations / step\n",
    "df_res.Vol_thresh = (df_res.Vol_thresh.astype(int) + 1) * step\n",
    "df_res.loc[df_res.Vol_thresh >= 4000, 'Vol_thresh'] = 100000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day-Night and Peek Off-Peek\n",
    "Day (6am-8pm) vs. night (8pm-6am)\n",
    "\n",
    "peak (7am-9am, 4pm-6pm) vs. off-peak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfh = results.copy()\n",
    "dfh['hour'] = pd.DatetimeIndex(dfh.datetime).hour  \n",
    "dfh = dfh.set_index('datetime')\n",
    "dfh.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daycond = (dfh.hour >= 6) & (dfh.hour < 20)\n",
    "peekcond = ( (dfh.hour >= 7) & (dfh.hour < 9) ) | ( (dfh.hour >= 16) & (dfh.hour < 18) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "dnres = pd.DataFrame(columns=['observ.', 'R2', 'MAPE', 'SMAPE', 'EMFR'])\n",
    "def add_to_res(dfh, dnres, desc, cond):\n",
    "    dfhc = dfh[cond]\n",
    "    r2 = r2_score(dfhc['volume'], dfhc['pred_ANN'])\n",
    "    MAPE = np.average(dfhc['mape'])\n",
    "    SMAPE = np.average(dfhc['smape'])\n",
    "    #ETCR = np.average(dfhc['err_capacityT'])\n",
    "    EMFR = np.average(dfhc['err_capacityP'])\n",
    "    obs = dfhc.shape[0]\n",
    "    dnres.loc[desc, :] = [obs, r2, MAPE, SMAPE, EMFR]\n",
    "    \n",
    "add_to_res(dfh, dnres, 'Day', daycond)   \n",
    "add_to_res(dfh, dnres, 'Night', ~daycond)   \n",
    "add_to_res(dfh, dnres, 'Peek', peekcond)\n",
    "add_to_res(dfh, dnres, 'Off-Peek', ~peekcond)   \n",
    "\n",
    "dnres.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detailed_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_frc = df_res.groupby('frc').agg({\n",
    "    'observations' : ['count', np.sum],\n",
    "    'R2' : [np.mean, np.median],\n",
    "    'MAPE' : [np.mean, np.median],\n",
    "    'SMAPE' : [np.mean, np.median],\n",
    "    'EMFR' : [np.mean, np.median],\n",
    "})\n",
    "res_frc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_gps = df_res.groupby('GPS_perc').agg({\n",
    "    'observations' : ['count', np.sum],\n",
    "    'R2' : [np.mean, np.median],\n",
    "    'MAPE' : [np.mean, np.median],\n",
    "    'SMAPE' : [np.mean, np.median],\n",
    "    'EMFR' : [np.mean, np.median],\n",
    "})\n",
    "res_gps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Granulation: {} minutes'.format(60 / gran_mul))    \n",
    "for i in range (1, 4):\n",
    "    print ('GPS_perc {}: {:.2f} - {:.2f}'\n",
    "           .format(i, gran_mul * df_res.GPS_avg[df_res.GPS_perc == i].min(), \n",
    "                   gran_mul * df_res.GPS_avg[df_res.GPS_perc == i].max()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_vol = df_res.groupby('Vol_thresh').agg({\n",
    "    'observations' : ['count', np.sum],\n",
    "    'R2' : [np.mean, np.median],\n",
    "    'MAPE' : [np.mean, np.median],\n",
    "    'SMAPE' : [np.mean, np.median],    \n",
    "    'EMFR' : [np.mean, np.median],\n",
    "})\n",
    "\n",
    "res_vol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log10, floor\n",
    "def round_sig(x, sig=2):\n",
    "    res = round(x, sig-int(floor(log10(abs(x))))-1)\n",
    "    return int(res) if res == int(res) else res\n",
    "        \n",
    "\n",
    "    \n",
    "def plot_bar(df, metric = 'R2', metric_agg = 'median', \n",
    "             title = None, x_labels = None, ymax = None, \n",
    "             file_pref = None, file_format = 'jpg'):\n",
    "    \n",
    "    if x_labels is None:\n",
    "        x_labels = df.index\n",
    "        \n",
    "    pos = np.arange(len(x_labels))\n",
    "    x_val = df[metric][metric_agg]\n",
    "\n",
    "    plt.figure()\n",
    "\n",
    "    bars = plt.bar(pos, x_val, align='center',  )\n",
    "\n",
    "    # Add title\n",
    "    if title is not None:\n",
    "        title = '{} ${}$ for {}'.format(\n",
    "            metric_agg.capitalize(), \n",
    "            ('R^2' if metric == 'R2' else '{} [\\%]'.format(metric)),\n",
    "            title\n",
    "        )\n",
    "        plt.title(title, alpha=0.8)\n",
    "        \n",
    "    plt.xticks(pos, x_labels, alpha=0.8)\n",
    "    if ymax is not None:\n",
    "        plt.ylim([0, ymax])\n",
    "    \n",
    "    #Remove ticks and labels\n",
    "    plt.tick_params(top=False, bottom=False, left=False, right=False, labelleft=False, labelbottom=True)\n",
    "\n",
    "    #remove frames\n",
    "    for spine in plt.gca().spines.values():\n",
    "        spine.set_visible(False)\n",
    "\n",
    "    height_shift = x_val.max() * 0.1\n",
    "    # direct label each bar with Y axis values\n",
    "    for bar in bars:\n",
    "        disp_val = round_sig(bar.get_height(), 2)\n",
    "        plt.gca().text(bar.get_x() + bar.get_width()/2, bar.get_height() - height_shift, disp_val, \n",
    "                     ha='center', color='w', fontsize=20)\n",
    "    \n",
    "    if file_pref is not None:\n",
    "        # Note = file_id is a global variable\n",
    "        filename = '{}_{}_{}_{}.{}'.format(file_pref, metric, metric_agg, file_id, file_format)\n",
    "        plt.savefig(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['EMFR', 'R2', 'MAPE', 'SMAPE']\n",
    "ymax_list = [None] * len(metrics)\n",
    "ymax_list = [10, 0.92, 38, 36]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHART_DIR = \"./MetricImgs\"\n",
    "import os\n",
    "if not os.path.exists(CHART_DIR):\n",
    "    os.makedirs(CHART_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m, ymax in zip(metrics, ymax_list):\n",
    "    plot_bar(res_gps, metric=m, \n",
    "             title = 'different avg probe counts / h', x_labels = ['Low', 'Med', 'High'], ymax = ymax,\n",
    "            file_pref = '{}/res_gps'.format(CHART_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m, ymax in zip(metrics, ymax_list):\n",
    "    plot_bar(res_frc, metric=m, \n",
    "             title = 'different FRCs', x_labels = ['Frc 1', 'Frc 2', 'Frc 3+'], ymax = ymax,\n",
    "            file_pref = '{}/res_frc'.format(CHART_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m, ymax in zip(metrics, ymax_list):\n",
    "    plot_bar(res_vol, metric=m, \n",
    "             title = 'different avg hourly volume thresholds', x_labels = ['0-1k', '1k-2k', '2k-3k', '3k+'], ymax = ymax,\n",
    "            file_pref = '{}/res_vol'.format(CHART_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
